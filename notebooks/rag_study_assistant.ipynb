{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab726ab",
   "metadata": {},
   "source": [
    "AI-Powered Study Assistant using Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "Course:Computer Networks  \n",
    "\n",
    "This project implements an AI-powered study assistant designed to help students\n",
    "answer questions from Computer Networks course materials using Retrieval-Augmented Generation (RAG).\n",
    "\n",
    "The system processes academic documents such as lecture notes and textbooks,\n",
    "retrieves relevant content using vector similarity search, and generates\n",
    "answers using an open-source language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9068bf",
   "metadata": {},
   "source": [
    "Technology Stack\n",
    "\n",
    "This project is implemented entirely using open-source tools:\n",
    "\n",
    "Language Model: Mistral (via Ollama, running locally)\n",
    "Embedding Model: Sentence-Transformers (`all-MiniLM-L6-v2`)\n",
    "Vector Database: ChromaDB (embedded, local)\n",
    "Document Processing:PDF-based academic materials\n",
    "Environment: Jupyter Notebook (Python)\n",
    "\n",
    "Open-source models were chosen to avoid API costs and to better understand\n",
    "the practical constraints of local deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac325b9f",
   "metadata": {},
   "source": [
    "Part 1: Data Collection and Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba29240",
   "metadata": {},
   "source": [
    "1.1 Dataset Overview\n",
    "\n",
    "For this project, I collected academic materials from my Computer Networks course.\n",
    "The dataset consists of lecture notes and reference material in PDF format, covering multiple layers of the network stack.\n",
    "\n",
    "Types of documents:\n",
    "- Lecture slide PDFs provided during coursework\n",
    "- Reference-style notes explaining networking concepts\n",
    "- Text-heavy PDFs with occasional diagrams and tables\n",
    "\n",
    "The documents primarily cover the following topics:\n",
    "- OSI and TCP/IP reference models\n",
    "- Physical and Data Link layers\n",
    "- Network layer concepts such as IP and routing\n",
    "- Transport layer protocols including TCP and UDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4925d2",
   "metadata": {},
   "source": [
    "1.2 Document Structure and Formatting\n",
    "\n",
    "Most documents follow a semi-structured format with headings, bullet points,\n",
    "and short explanatory paragraphs. However, the structure is not consistent\n",
    "across all PDFs.\n",
    "\n",
    "Some documents are slide-based with minimal text per page, while others are\n",
    "dense text documents resembling textbook chapters. Diagrams are often embedded\n",
    "as images, and tables are sometimes split across pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f7d844",
   "metadata": {},
   "source": [
    "1.3 Observed Challenges in the Dataset\n",
    "\n",
    "After inspecting the raw PDFs, I observed several challenges that affect\n",
    "automatic text processing:\n",
    "\n",
    "1. Inconsistent formatting: Different PDFs use different heading styles, making it difficult to rely on document structure alone.\n",
    "2. Broken text flow: In some cases, sentences are split across lines or pages\n",
    "   during text extraction.\n",
    "3. Tables and diagrams: Tables are converted into plain text with lost alignment,\n",
    "   and diagrams do not contain meaningful extractable text.\n",
    "4. Technical terminology: Networking concepts include abbreviations and protocol\n",
    "   names (e.g., TCP, UDP, ARP) that require accurate retrieval to avoid confusion.\n",
    "\n",
    "These challenges reflect real-world academic data and motivate the need for\n",
    "careful chunking, retrieval, and prompt design in later stages of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf56a1a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfplumber'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpdfplumber\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      4\u001b[0m data_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/raw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pdfplumber'"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"../data/raw\")\n",
    "\n",
    "pdf_files = list(data_path.glob(\"*.pdf\"))\n",
    "print(f\"Found {len(pdf_files)} PDF files\")\n",
    "\n",
    "sample_pdf = pdf_files[0]\n",
    "print(f\"Inspecting file: {sample_pdf.name}\")\n",
    "\n",
    "with pdfplumber.open(sample_pdf) as pdf:\n",
    "    first_page = pdf.pages[0]\n",
    "    text = first_page.extract_text()\n",
    "\n",
    "print(\"----- Extracted Text (First Page) -----\")\n",
    "print(text[:1500]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
